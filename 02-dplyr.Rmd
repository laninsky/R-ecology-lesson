---
title: Manipulating, analyzing and exporting data with tidyverse
author: Data Carpentry contributors
---

```{r, echo=FALSE, purl=FALSE, message = FALSE}
source("setup.R")
surveys <- read.csv("data/portal_data_joined.csv")
suppressWarnings(surveys$date <- lubridate::ymd(paste(surveys$year,
                                                      surveys$month,
                                                      surveys$day,
                                                      sep = "-")))
```

### Manipulating and analyzing data with dplyr

Kia ora

-- in this session we are going to learn about a couple of packages within the tidyverse that make it easier to pull things we are interested in out of data frames, as well as doing manipulations directly on this data 

-- Start up R studio, red sticky if any issues

-- Link to class etherpad is up on whiteboard

-- In it is the link to today's lesson if you want to revisit it

-- Feel free to leave feedback in it: I get better at teaching based on feedback

-- I'll also put all the code I write today in the etherpad so I think you'll get most out of following along and trying to do the code rather than taking notes

Starting off with the learning objectives...



------------

> ### Learning Objectives
> * We are specifically going to cover using dplyr to select columns and rows we are interested in
> * How to use pipes to whiz our data from one fuction to another
> * how to add new columns based on doing stuff to existing columns
> * how to split our data up, do stuff, and then summarize the output so we can get combined summary statistics and few other technical bits and pieces 

------------

# Data Manipulation using **`dplyr`** and **`tidyr`**

Packages in R are basically sets of additional functions that let you do more stuff. 

So far we've been using functions built into R, also known as base R.

packages give you access to more of them.

To start off load the package tidyverse:

```{r, eval=FALSE,message = FALSE, purl = FALSE}
## Before you use a package the first time you need to install it
install.packages("tidyverse")

## then load the tidyverse packages, incl. dplyr
library("tidyverse")

# Next time you go to R, you don't have to do 
# install.packages step
```

Tidyverse is an "umbrella-package" that installs several packages useful for data analysis which
work together well such as **`tidyr`**, **`dplyr`**, and **`ggplot2`**


**`tidyverse`**  tries to address 3 common issues 
1. The results from a base R function sometimes depend on the type of data.
2. Using R expressions in a non standard way can be confusing for new learners.
3. Hidden arguments, having default operations that new learners are not aware of.

# Tidyverse helps with a problem in base R
When you read in data using base R, there is a weird thing where if you don't know about the hidden options in the function, that it will coerce data to a data type known as factors. This can make stuff speedier for R to do analyses, but also trips you up when trying to do stuff with your data. 

The **`tidyverse`** package avoids this problem 

We'll read in our data using the `read_csv()` function, from the tidyverse package **`readr`**, instead of `read.csv()` that you might see from base R in other people's code.

```{r, results = 'hide', purl = FALSE}
# read_csv is part of the tidyverse package readr
# compared to read.csv that you might see elsewhere
surveys <- read_csv("data/portal_data_joined.csv")
# this gives a description of what the tidyverse thinks the data type of each column is

## inspect the data
str(surveys)

## preview the data
# View(surveys)
```

Notice that the class of the data is now `tbl_df`

This is referred to as a "tibble". Tibbles are very similar to a data frame. For our purposes the only differences are that:

1. It displays the data type of each column under its name, it only prints the first few rows of data and only as many columns as fit on one screen.
2. Columns of class `character` are never converted into factors.

STICKIES

In a moment we are going to get in to the most common functions we use with the tidyverse package dplyr, but first...

## What are **`dplyr`** and **`tidyr`**?

**`dplyr`** is a package for
making tabular data manipulation easier than using the subsetting we talked about previously. 

It pairs nicely with **`tidyr`** which enables you to swiftly reshape your data for plotting and use by different R functions. Sometimes we want data sets where we have one row per measurement. Sometimes we want a data frame rows are clumps of measurements like plots or species. 

To learn more about **`dplyr`** and **`tidyr`** after the workshop, you may want to check out this
[handy data transformation with **`dplyr`** cheatsheet](https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf) and this [one about **`tidyr`**](https://github.com/rstudio/cheatsheets/raw/master/data-import.pdf).

We're going to learn some of the most common **`dplyr`** functions:

```{r, eval=FALSE,results = 'hide', purl = FALSE}
#subset columns. seleCt (c = columns)
select()
# subset rows on conditions. filteR (r = rows)
filter()
#create new columns by using information from other columns
mutate()
#create summary statisitcs on grouped data
group_by() %>% summarize() # I'll explain the crazy %>% thing in a minute
# sort results
arrange()
# count discrete values
count()
```

STICKIES

## Selecting columns and filtering rows


```{r, results = 'hide', purl = FALSE}
#To select columns of a data frame, use `select()`
# First argument is the data frame (`surveys`)
# subsequent arguments are the columns to keep.
select(surveys, plot_id, species_id, weight)
```


```{r, results = 'hide', purl = FALSE}
# To select all columns *except* certain ones, put a # "-" in front of the variable to exclude it.
select(surveys, -record_id, -species_id)
```

If we want to pull out ROWS we are interested in, we use  `filter()`:

```{r, purl = FALSE}
# Pulling out rows
filter(surveys, year == 1995)
```

Boom folks, that's the first three learning objectives 
- describing what dplyr and tidyr are useful for
- selecting columns using select
- selecting rows using filter

STICKIES

## Pipes
What if you want to get a subset of both rows and columns we can do this in 3 ways

1) using intermediate steps

2) nested functions

3) pipes

What if you want to select and filter the same dataset? There are three
ways to do this: use intermediate steps, nested functions, or pipes.

```{r, purl = FALSE}
## How to select and filter the same data set

# 1. With intermediate steps, you create a temporary data frame and use
# that as input to the next function, like this:

surveys2 <- filter(surveys, weight < 5)
surveys_sml <- select(surveys2, species_id, sex, weight)
```

Nothing wrong with this but it creates a lot of objects that can be tricky to keep track of

```{r, purl = FALSE}
#2. You can also nest functions (i.e. one function inside of another), like this:

# Rewrite surveys_sml, but replace surveys2 in it
surveys_sml <- select(filter(surveys, weight < 5), species_id, sex, weight)
```

This works kind of like BEDMAS - you do the innermost functions first

However with a ton of different manipulations this gets tricky because it can be hard to work out the order to do things

The last option, *pipes* let you take the output of one function and shoot it directly to the next.

```{r, purl = FALSE}
#3. Use pipes to shoot the output of one function to another
# a "pipe" looks like %>%  (the shortcut is shift+ctrl+m in win and shift+cmd+m in a mac)

surveys %>%
  filter(weight < 5) %>%
  select(species_id, sex, weight)

# Since `%>%` takes the object on its left and passes it as the first argument to the 
# function on its right, we don't need to explicitly include the data frame as an 
# argument

```

You might find it helpful to think of %>% as "then"

For instance in this example we took the data frame `surveys`, *then* we `filter`ed for rows with `weight < 5`, *then* we `select`ed columns `species_id`, `sex`, and `weight`. 

```{r, eval=FALSE,purl = FALSE}
#If we want to save our output we need to assign it to an object
surveys_sml <- surveys %>%
  filter(weight < 5) %>%
  select(species_id, sex, weight)

surveys_sml
```


```{r, eval=FALSE,purl = FALSE}
### Challenge {.challenge}
# Using pipes, subset the `surveys` data to include animals collected before
# 1995 and retain only the columns `year`, `sex`, and `weight`.
```

```{r, answer=TRUE, eval=FALSE, purl=FALSE}
surveys %>%
     filter(year < 1995) %>%
     select(year, sex, weight)
```

STICKIES

### Mutate

Sometimes we are going to want to create new columns based on info in existing columns

In the tidyverse we do this by using mutate

```{r, eval=FALSE,purl = FALSE}
# To create a new column of weight in kg
surveys %>%
  mutate(weight_kg = weight / 1000)
```

When we do this you can see in the tibble summary a new column called weight_kg



```{r, purl = FALSE}
# You can also create a second new column based on the first new column within the same # call of `mutate()`:
surveys %>%
  mutate(weight_kg = weight / 1000,
         weight_kg2 = weight_kg * 2)
```

If you don't want to see all the rows you could pipe it to`head()`. Even though head() is not a dplyr function,  as long as the **`dplyr`** or `magrittr` package is loaded you an use pipes

```{r, purl = FALSE}
surveys %>%
  mutate(weight_kg = weight / 1000) %>%
  head()
```

If we want we could filter out the NAs

```{r, purl = FALSE}
# Filtering out NAs. You might remember ! = is NOT so !is.na means "is not NA"
surveys %>%
  filter(!is.na(weight)) %>%
  mutate(weight_kg = weight / 1000) %>%
  head()
```

### Challenge {.challenge}

# Create a new data frame from the `surveys` data that meets the following criteria: 
# -- only has the `species_id` column and a new column called `hindfoot_half` 
# -- hindfoot_half contains values that are half the `hindfoot_length` values.
# -- Also, in this `hindfoot_half` column, there are no `NA`s and all values are less
# than 30.
**Hint**: think about how the commands should be ordered to produce this data frame!

```{r, answer=TRUE, eval=FALSE, purl=FALSE}
surveys_hindfoot_half <- surveys %>%
     filter(!is.na(hindfoot_length)) %>%
     mutate(hindfoot_half = hindfoot_length / 2) %>%
     filter(hindfoot_half < 30) %>%
     select(species_id, hindfoot_half)
```

Congrats guys  - you've knocked another two learning objectives off

-- you've learned about pippes AND creating new columns using mutate

### Split-apply-combine data analysis and the summarize() function

Our next section is going to show a common approach where we split data into groups, analyses them, and then smush results back together

We'll do this using dplyr's group_by function and summarie function

```{r, purl = FALSE}
# group_by() specifies the column names that you want to calculate summary statistics
# summarize() collapses each group into a single-row summary (UK spelling works too)
surveys %>%
  group_by(sex) %>%
  summarize(mean_weight = mean(weight, na.rm = TRUE))
```

group_by = what do you want to calculate stats for?
summarize = what stuff do you want calculated?


```{r, purl = FALSE}
# You can also group by multiple columns:
surveys %>%
  group_by(sex, species_id) %>%
  summarize(mean_weight = mean(weight, na.rm = TRUE))
```

If you want to display more data, 

```{r, purl = FALSE}
#You can use the `print()` function at the end of your chain with the argument `n` # specifying the number of lines
surveys %>%
  group_by(sex, species_id) %>%
  summarize(mean_weight = mean(weight, na.rm=TRUE)) %>%
  print(n = 15)

# Repeat with n = 24, n = 72
```

OK so this isinteresting- even though we used na.rm, we still have NAN in these columns

The problem is that when we grouped by species_id and sex some of these combos don't have any any animals with weight info, so they have to return NaNs


To avoid this, we can remove the missing values for weight before we
attempt to calculate the summary statistics on weight. Because the missing
values are removed first, we can omit `na.rm = TRUE` when computing the mean:

```{r, purl = FALSE}
surveys %>%
  filter(!is.na(weight)) %>%
  group_by(sex, species_id) %>%
  summarize(mean_weight = mean(weight))
```


You can also summarize multiple variables at the same time (and not necessarily on the same variable). For instance, we could add a column indicating the minimum weight for each species for each sex:

```{r, purl = FALSE}
# You can summarize multiple variables at the same time (mean_weight, min_weight)
surveys %>%
  filter(!is.na(weight)) %>%
  group_by(sex, species_id) %>%
  summarize(mean_weight = mean(weight),
            min_weight = min(weight))
```

We can also sort the result of a query to inspect the values using arrange(). For instance, we can sort on `min_weight` to put the lighter species first:


```{r, purl = FALSE}
# Using arrange to sort from smaller min weights to bigger min weights
surveys %>%
  filter(!is.na(weight)) %>%
  group_by(sex, species_id) %>%
  summarize(mean_weight = mean(weight),
            min_weight = min(weight)) %>%
  arrange(min_weight)
```


```{r, purl = FALSE}
# To sort in descending order, we need to add the `desc()` function. 
# If we want to sort the results by decreasing order of mean weight:
surveys %>%
  filter(!is.na(weight)) %>%
  group_by(sex, species_id) %>%
  summarize(mean_weight = mean(weight),
            min_weight = min(weight)) %>%
  arrange(desc(mean_weight))
```

#### Counting

When working with data, we often want to know the number of observations for each factor or combination of factors. To do this wel'll use dplyr's count() function

```{r, purl = FALSE}
# To count number of rows of data for each sex
surveys %>%
    count(sex) 
```


```{r, purl = FALSE}
# count() also has a  `sort` argument:  
surveys %>%
    count(sex, sort = TRUE) 
```

```{r purl = FALSE}
# Can also count *combination of factors*, such as `sex` and `species`, 
surveys %>%
  count(sex, species) 
```

If youdon't want to sort according to your count you can use arrange() to sort the table according to other stuff. 


```{r purl = FALSE}
# e.g. to arrange the table above in (i) an alphabetical order of the levels of the 
# species and (ii) in descending order of the count:

surveys %>%
  count(sex, species) %>%
  arrange(species, desc(n))
```

STICKIES

### Challenge {.challenge}

#1. How many animals were caught in each `plot_type` surveyed?

```{r, answer=TRUE, purl=FALSE}
surveys %>%
    count(plot_type) 
```

# 2. Use `group_by()` and `summarize()` to find the mean, min, and max hindfoot
# length for each species (using `species_id`). Also add the number of
# observations (hint: see `?n`).

```{r, answer=TRUE, purl=FALSE}
 surveys %>%
     filter(!is.na(hindfoot_length)) %>%
     group_by(species_id) %>%
     summarize(
         mean_hindfoot_length = mean(hindfoot_length),
         min_hindfoot_length = min(hindfoot_length),
         max_hindfoot_length = max(hindfoot_length),
         n = n()
     )
```

#3. What was the heaviest animal measured in each year? Return the columns `year`,
# `genus`, `species_id`, and `weight`.

```{r, answer=TRUE, purl=FALSE}
surveys %>%
     filter(!is.na(weight)) %>%
     group_by(year) %>%
     filter(weight == max(weight)) %>%
     select(year, genus, species, weight) %>%
     arrange(year)
```

Alright guys, we've covered 2 more learning objectives, only 4 mre to go! You now know about the split-apply-combine concept and how to get summaries for groups of yoru data.

### Reshaping with gather and spread

Now we are going to switch gears and use functions provided by tidyr to reshape our data while still following the "tidy data rules" (if you did the spreadsheet session you would have learned these, but for the rest of us)
1. Each variable has its own column
2. Each observation has its own row
3. Each value must have its own cell
4. Each type of observational unit forms a table

The 4th rule is one that I find a little more difficult to get my head around, so let's work through this:

In `surveys` , the rows of `surveys` are records, and columns are values such the weight or sex of each animal associated with each record. 

If we wanted to compare the different mean weight of each species between plots we'd want to make a different table because now instead of the rows being records, they'd be mean weights, and instead of columns being weight and sex, they'd now be species.

Our observational units are now different, so we want this to be a different table!

The key point here is that we are still following a tidy data structure i.e. a rectangle, but we have **reshaped** the data

The opposite transformation would be to transform column names into values of a variable.

We can do both these of transformations with two `tidyr` functions, `spread()` and `gather()`.

#### Spreading

`spread()` takes three principal arguments:

1. the data 
2. the *key* column variable whose values will become new column names.  
3. the *value* column variable whose values will fill the new column variables.

Further arguments include `fill` which, if set, fills in missing values with  the value provided.

So let's test out spread to create a new object with the mean weight of eachspecies in each plot over the entire survey period. 

First we are going to do a little manipulation of our data set:

```{r, purl=FALSE}
# We use `filter()`, `group_by()` and `summarise()` to filter our datasets
# and create a new variable for the `mean_weight`. 
# Pipe is Shift+Ctrl+M
surveys_gw <- surveys %>%
  filter(!is.na(weight)) %>%
  group_by(genus, plot_id) %>%
  summarize(mean_weight = mean(weight))

str(surveys_gw)
```

`surveys_gw` has observations for each plot across multiple rows, 196 observations of 13 variables. 

```{r, eval=FALSE,purl=FALSE}
# Species ?
```

Using `spread()` to key on `genus` (so column names will now be genus) with values - cells - from `mean_weight` this becomes 24 observations of 11 variables, one row for each plot. We again use pipes:

```{r, purl=FALSE}
surveys_spread <- surveys_gw %>%
  spread(key = genus, value = mean_weight)

str(surveys_spread)
```

![](img/spread_data_R.png)

We could now plot comparisons between the weight of species in different plots,  although we may wish to fill in the missing values first.

```{r, purl=FALSE}
surveys_gw %>%
  spread(genus, mean_weight, fill = 0) %>%
  head()
```

#### Gathering

The opposing situation could occur if we had been provided with data where the genus names are column names, but we wish to treat them as values within genus column instead.

In this situation we are gathering the column names and turning them into a pair of new variables. One variable represents the column names as values, and the other variable contains the values previously associated with the column names.

`gather()` takes four principal arguments:

1. the data
2. the *key* column variable we wish to create from column names.
3. the *values* column variable we wish to create and fill with values 
associated with the key.
4. the names of the columns we use to fill the key variable (or to drop).

So this is reversing the process we did creating `surveys_spread` from `surveys_gw`. Now we are going from `surveys_spread` back into something that looks like `surveys_gw` 

```{r, purl=FALSE}
#key called `genus` and value called `mean_weight`, use all columns except `plot_id`
# we drop `plot_id` column with a minus sign.

surveys_gather <- surveys_spread %>%
  gather(key = genus, value = mean_weight, -plot_id)

str(surveys_gather)
```

![](img/gather_data_R.png)

Note that now the `NA` genera are included in the re-gathered format. Spreading and then gathering can be a useful way to balance out a dataset so every replicate has the same composition.

This can be handy wen you are writing code to automate stuff.

We could also have used a specification for what columns to include. This can be useful if you have a large number of identifying columns, and it's easier to specify what to gather than what to leave alone. And if the columns are in a row, we don't even need to list them all out - just use the `:` operator!

```{r, purl=FALSE}
# if the columns are in a row, we don't even need to list them all out - just use the 
# `:` operator!
surveys_spread %>%
  gather(key = genus, value = mean_weight, Baiomys:Spermophilus) %>%
  head()
```

If we've got time, otherwise go straight to exporting

> ### Challenge {.challenge}
>
> 1. Spread the `surveys` data frame with `year` as columns, `plot_id` 
>   as rows, and the
>   number of genera per plot as the values. You will need to summarize before
>   reshaping, and use the function `n_distinct()` to get the number of unique
>   genera within a particular chunk of data. It's a powerful function! See
>   `?n_distinct` for more.
> 
> ```{r, answer=TRUE, purl=FALSE}
> rich_time <- surveys %>%
>   group_by(plot_id, year) %>%
>   summarize(n_genera = n_distinct(genus)) %>%
>   spread(year, n_genera)
> 
> head(rich_time)
> ```
>
> 2. Now take that data frame and `gather()` it again, so each row is a unique
>    `plot_id` by `year` combination.
>
> ```{r, answer=TRUE, purl=FALSE}
> rich_time %>%
>   gather(year, n_genera, -plot_id)
> ```
>
> 3. The `surveys` data set has
>    two measurement columns: `hindfoot_length` and `weight`.  This makes it
>    difficult to do things like look at the relationship between mean values of
>    each measurement per year in different plot types. Let's walk through a
>    common solution for this type of problem. First, use `gather()` to create a
>     dataset where we have a key column called `measurement` and a
>    `value` column that takes on the value of either `hindfoot_length` or
>    `weight`. *Hint*: You'll need to specify which columns are being gathered.
>
> ```{r, answer=TRUE, purl=FALSE}
> surveys_long <- surveys %>%
>   gather(measurement, value, hindfoot_length, weight)
> ```
>
> 4. With this new data set, calculate the average of each
>    `measurement` in each `year` for each different `plot_type`. Then
>    `spread()` them into a data set with a column for `hindfoot_length` and
>    `weight`. *Hint*: You only need to specify the key and value
>    columns for `spread()`.
>
> ```{r, answer=TRUE, purl=FALSE}
> surveys_long %>%
>   group_by(year, measurement, plot_type) %>%
>   summarize(mean_value = mean(value, na.rm=TRUE)) %>%
>   spread(measurement, mean_value)
> ```


# Exporting data

Similar to the `read_csv()` function used for reading CSV files into R, there is a `write_csv()` function that generates CSV files from data frames.

Before using `write_csv()`, we are going to create a new folder, `data_output`, in our working directory that will store this generated dataset. 

It's good practice to keep processed data separate from raw data so we don't accidentally brick our raw data.

In preparation for our next lesson on plotting, we are going to prepare a cleaned up version of the data set that doesn't include any missing data.

```{r, purl=FALSE}
#Let's start by removing observations of animals for which `weight` and 
# `hindfoot_length` are missing, or the `sex` has not been determined:

surveys_complete <- surveys %>%
  filter(!is.na(weight),           # remove missing weight
         !is.na(hindfoot_length),  # remove missing hindfoot_length
         !is.na(sex))                # remove missing sex
```

We are also going to remove observations for rare species (i.e., that have been observed less than 50 times) for ease of plotting.

We will do this in two steps: 
1) data set that counts how often each species has been observed, and filter out the rare species; 
2) we will extract only the observations for these more common species:

```{r, purl=FALSE}
## Extract the most common species_id
species_counts <- surveys_complete %>%
    count(species_id) %>% 
    filter(n >= 50)

## Only keep the most common species
surveys_complete <- surveys_complete %>%
  filter(species_id %in% species_counts$species_id)
```

To make sure that everyone has the same data set, check that `surveys_complete`
has `r nrow(surveys_complete)` rows and `r ncol(surveys_complete)` columns by
typing `dim(surveys_complete)`.

Now that our data set is ready, we can save it as a CSV file in our `data_output`
folder.

```{r, purl=FALSE, eval=FALSE}
write_csv(surveys_complete, path = "data_output/surveys_complete.csv")
```

```{r, purl=FALSE, eval=TRUE, echo=FALSE}
if (!dir.exists("data_output")) dir.create("data_output")
write_csv(surveys_complete, path = "data_output/surveys_complete.csv")
```


```{r, child="_page_built_on.Rmd"}
```
